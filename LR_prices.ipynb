{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a program that use supervised machine learning to predict stock prices. \n",
    "\n",
    "The script uses regularized linear regression that takes a series of continuous stock prices (Highest in the day) to predict stock prices (highest in the day) given immediately after. The data used is Tesla's historical stock prices downloaded from https://finance.yahoo.com/quote/TSLA/history?p=TSLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Parameters:\n",
    "\n",
    "filename = 'TSLA.csv'\n",
    "lag = 15 # Using the past 15 prices to predict the next\n",
    "iterations = 300 # Train with 300 iterations\n",
    "threshold = 9e9 # Stop training when cost exceeds the threshold\n",
    "\n",
    "alpha_list = [1, 0.1, 0.01] # Training step size\n",
    "lam_list = [0.01, 0.001, 0.0001] # Regularier parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read the data from csv sheets. If using lag=15, the script organizes prices of 15 continuous dates into a training example, and uses the 16th price as label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: \n",
      "993 15\n",
      "993\n"
     ]
    }
   ],
   "source": [
    "# Data Management:\n",
    "X = []\n",
    "Y = []\n",
    "with open(filename, 'r') as djiFile:\n",
    "    dji = csv.reader(djiFile)\n",
    "    next(dji)\n",
    "    row_buff = []\n",
    "    \n",
    "    for row in dji:\n",
    "        if len(row_buff) < lag:\n",
    "            row_buff.append(float(row[2]))\n",
    "        else:\n",
    "            X.append(row_buff)\n",
    "            row_buff = row_buff[1:]\n",
    "            row_buff.append(float(row[2]))\n",
    "            Y.append(numpy.array(float(row[2])))\n",
    "    \n",
    "X = numpy.array(X)\n",
    "Y = numpy.array(Y)\n",
    "num_examples = numpy.size(X,0)\n",
    "num_features = numpy.size(X,1)\n",
    "\n",
    "print(\"Dataset size: \")\n",
    "print(numpy.size(X,0), numpy.size(X,1))\n",
    "print(numpy.size(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the stock prices dealing with can sometimes be very high. If using DJIA it could be around 20,000, the script use mean normalization to preprocess the data. A feature of 1.0 is also added to all examples.\n",
    "\n",
    "The normalized data is then shuffled, in case the training is influenced by potential trends over larger time periods. \n",
    "\n",
    "The script then separates all examples into training set, validation set, and test set, in the ratio of 60%:20%:20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Normalization:\n",
    "X_norm = numpy.zeros((num_examples, num_features), dtype=float)\n",
    "X_mean = numpy.zeros((1, num_features), dtype=float)\n",
    "X_std = numpy.zeros((1, num_features), dtype=float)\n",
    "\n",
    "for j in range(0, num_features):\n",
    "    X_mean[0,j] = numpy.mean(X[:,j])\n",
    "    X_std[0,j] = numpy.std(X[:,j])\n",
    "    X_norm[:,j] = (X[:,j] - X_mean[0,j]) / X_std[0,j]\n",
    "    \n",
    "Y_norm = (Y - numpy.mean(Y)) / numpy.std(Y)\n",
    "\n",
    "# Add first feature as ones:\n",
    "col_first = numpy.ones([numpy.size(X,0), 1])\n",
    "X_norm = numpy.hstack((col_first, X_norm))\n",
    "num_features += 1\n",
    "\n",
    "# Shuffle data:\n",
    "X_norm, Y_norm = shuffle(X_norm, Y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size =  596 16\n",
      "Validation set size =  198\n",
      "Test set size =  199\n",
      "\n",
      "First three training examples: \n",
      "[[ 1.          2.68377766  2.21098085  1.88764249  2.14164381  2.44340912\n",
      "   2.17214968  1.99619122  1.75412677  1.49786913  1.49135436  1.39173772\n",
      "   1.08003592  1.11391572  0.5750608   0.45521856]\n",
      " [ 1.          0.16539199  0.21084699  0.15973434  0.12759969  0.11139001\n",
      "   0.06530273 -0.00880898 -0.04711521 -0.05165879 -0.09998273 -0.09542066\n",
      "  -0.10504283 -0.08734699 -0.04638823 -0.05745645]\n",
      " [ 1.          2.7575316   2.57421032  2.52989499  2.64333594  2.52521833\n",
      "   2.48810754  2.44415086  2.38589824  2.3514499   2.27276091  2.215813\n",
      "   2.21644523  2.46548686  2.46239572  2.36454192]]\n",
      "\n",
      "First three labels: \n",
      "[ 0.1476996  -0.0505277   2.32169082]\n"
     ]
    }
   ],
   "source": [
    "# Data separated into sets:\n",
    "Xtrain = X_norm[0 : round(num_examples*0.6)]\n",
    "Xval = X_norm[round(num_examples*0.6) : round(num_examples*0.8)]\n",
    "Xtest = X_norm[round(num_examples*0.8) :]\n",
    "\n",
    "Ytrain = Y_norm[0 : round(num_examples*0.6)]\n",
    "Yval = Y_norm[round(num_examples*0.6) : round(num_examples*0.8)]\n",
    "Ytest = Y_norm[round(num_examples*0.8) :]\n",
    "\n",
    "size_train = numpy.size(Xtrain, 0)\n",
    "size_val = numpy.size(Xval, 0)\n",
    "size_test = numpy.size(Xtest, 0)\n",
    "\n",
    "print(\"Training set size = \", numpy.size(Xtrain,0), numpy.size(Xtrain,1))\n",
    "print(\"Validation set size = \", numpy.size(Xval,0))\n",
    "print(\"Test set size = \", numpy.size(Xtest,0))\n",
    "print(\"\\nFirst three training examples: \")\n",
    "print(Xtrain[0:3])\n",
    "print(\"\\nFirst three labels: \")\n",
    "print(Ytrain[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set will output a parameter for every alpha and lambda. The training iterations for certain alpha and lambda will be skipped if the cost increases exceeding the threshold.\n",
    "\n",
    "The validation set is used to find optimal alpha and lambda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set up:\n",
    "param_all = numpy.zeros((num_features, len(alpha_list), len(lam_list)))\n",
    "    # Collection of all parameters learned for every alpha and lambda combination\n",
    "cost_opt = 999999\n",
    "alpha_opt_index = 0;\n",
    "lam_opt_index = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with alpha =  1  and lambda =  0.01\n",
      " Skipped\n",
      " cost =  [3.14971253e+11]\n",
      "Training with alpha =  1  and lambda =  0.001\n",
      " Skipped\n",
      " cost =  [3.14617462e+11]\n",
      "Training with alpha =  1  and lambda =  0.0001\n",
      " Skipped\n",
      " cost =  [3.14582084e+11]\n",
      "Training with alpha =  0.1  and lambda =  0.01\n",
      " cost =  [0.00841447]\n",
      "Training with alpha =  0.1  and lambda =  0.001\n",
      " cost =  [0.00573881]\n",
      "Training with alpha =  0.1  and lambda =  0.0001\n",
      " cost =  [0.00547118]\n",
      "Training with alpha =  0.01  and lambda =  0.01\n",
      " cost =  [0.0130188]\n",
      "Training with alpha =  0.01  and lambda =  0.001\n",
      " cost =  [0.0121306]\n",
      "Training with alpha =  0.01  and lambda =  0.0001\n",
      " cost =  [0.01204177]\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "\n",
    "for a in range(0, len(alpha_list)):\n",
    "    alpha = alpha_list[a]\n",
    "    \n",
    "    for l in range(0, len(lam_list)):\n",
    "        lam = lam_list[l]\n",
    "        \n",
    "        param = numpy.zeros((num_features, 1), dtype=float)\n",
    "        cost = 0\n",
    "        print(\"Training with alpha = \", alpha, \" and lambda = \", lam)\n",
    "        \n",
    "        for r in range(0, iterations):\n",
    "            param_temp = numpy.zeros(numpy.size(param))\n",
    "\n",
    "            for j in range(0, num_features): \n",
    "\n",
    "                grad = 0\n",
    "                for i in range(0, size_train):\n",
    "                    grad += (Xtrain[i]@param - Ytrain[i]) * Xtrain[i,j]\n",
    "                grad = (1/size_train) * grad\n",
    "                if j != 0:\n",
    "                    grad += (lam/size_train) * param[j]  \n",
    "                param_temp[j] = param[j] - alpha * grad\n",
    "\n",
    "            for j in range(0, num_features): \n",
    "                param[j] = param_temp[j]\n",
    "\n",
    "            # Cost:\n",
    "            sumSqrError = 0\n",
    "            for i in range(0, size_train):\n",
    "                sumSqrError += (Xtrain[i] @ param - Ytrain[i]) ** 2\n",
    "            sumSqrParam = 0\n",
    "            for j in range(1, num_features):\n",
    "                sumSqrParam += param[j] ** 2\n",
    "            cost = (1/(2*size_train)) * sumSqrError + lam * sumSqrParam\n",
    "            #print(\"Iteration \", r+1, \", cost = \", cost, end='\\n')\n",
    "            \n",
    "            if cost > threshold:\n",
    "                print(\" Skipped\")\n",
    "                break\n",
    "            \n",
    "        print(\" cost = \", cost, end='\\n')\n",
    "        for j in range(0, num_features):\n",
    "            param_all[j,a,l] = param[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set has cost =  [0.006195]\n",
      "alpha =  0.1\n",
      "lambda =  0.0001\n"
     ]
    }
   ],
   "source": [
    "# Use validation set to find optimal alpha and lambda:\n",
    "\n",
    "for a in range(0, len(alpha_list)):\n",
    "    for l in range(0, len(lam_list)):\n",
    "        sumSqrError = 0\n",
    "        sumSqrParam = 0\n",
    "        for i in range(0, size_val):\n",
    "            sumSqrError += (Xval[i] @ param_all[:,a,l] - Yval[i]) ** 2\n",
    "        for j in range(1, num_features):\n",
    "            sumSqrParam += param[j] ** 2\n",
    "        cost = (1/(2*size_val)) * sumSqrError + lam_list[l] * sumSqrParam\n",
    "        \n",
    "        if cost < cost_opt:\n",
    "            cost_opt = cost\n",
    "            alpha_opt_index = a\n",
    "            lam_opt_index = l\n",
    "\n",
    "param = param_all[:, alpha_opt_index, lam_opt_index]\n",
    "print(\"Validation set has cost = \", cost_opt)\n",
    "print(\"alpha = \", alpha_list[alpha_opt_index])\n",
    "print(\"lambda = \", lam_list[lam_opt_index])\n",
    "#print(\"Parameters: \", param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set examines the results of learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results:\n",
      "Prediction =  308.93 , Y =  317.42\n",
      "Prediction =  243.52 , Y =  253.89\n",
      "Prediction =  296.67 , Y =  303.95\n",
      "Prediction =  255.88 , Y =  264.55\n",
      "Prediction =  272.42 , Y =  330.0\n",
      "Prediction =  213.71 , Y =  220.33\n",
      "Prediction =  224.72 , Y =  235.54\n",
      "Prediction =  1434.35 , Y =  1794.99\n",
      "Prediction =  271.07 , Y =  266.77\n",
      "Prediction =  246.67 , Y =  257.82\n",
      "Prediction =  253.45 , Y =  256.14\n",
      "Prediction =  280.95 , Y =  279.91\n",
      "Prediction =  254.02 , Y =  258.33\n",
      "Prediction =  253.58 , Y =  266.07\n",
      "Prediction =  771.47 , Y =  796.4\n",
      "Prediction =  601.66 , Y =  653.0\n",
      "Prediction =  220.22 , Y =  223.22\n",
      "Prediction =  347.76 , Y =  349.95\n",
      "Prediction =  301.49 , Y =  304.0\n",
      "Prediction =  314.64 , Y =  321.53\n",
      "Prediction =  343.76 , Y =  357.6\n",
      "Prediction =  509.77 , Y =  516.65\n",
      "Prediction =  348.07 , Y =  354.48\n",
      "Prediction =  246.35 , Y =  257.21\n",
      "Prediction =  310.15 , Y =  311.85\n",
      "Prediction =  336.7 , Y =  352.3\n",
      "Prediction =  569.84 , Y =  650.88\n",
      "Prediction =  811.06 , Y =  824.75\n",
      "Prediction =  303.39 , Y =  322.44\n",
      "Prediction =  325.91 , Y =  323.94\n",
      "Prediction =  340.91 , Y =  357.02\n",
      "Prediction =  394.48 , Y =  422.01\n",
      "Prediction =  336.04 , Y =  323.47\n",
      "Prediction =  888.02 , Y =  863.5\n",
      "Prediction =  310.89 , Y =  311.25\n",
      "Prediction =  197.3 , Y =  199.98\n",
      "Prediction =  327.51 , Y =  347.44\n",
      "Prediction =  715.12 , Y =  774.95\n",
      "Prediction =  241.27 , Y =  245.18\n",
      "Prediction =  220.31 , Y =  230.31\n",
      "Prediction =  299.16 , Y =  300.84\n",
      "Prediction =  302.73 , Y =  309.62\n",
      "Prediction =  222.46 , Y =  227.19\n",
      "Prediction =  295.61 , Y =  307.01\n",
      "Prediction =  240.06 , Y =  241.99\n",
      "Prediction =  315.36 , Y =  309.4\n",
      "Prediction =  682.22 , Y =  968.99\n",
      "Prediction =  261.69 , Y =  275.37\n",
      "Prediction =  300.74 , Y =  316.35\n",
      "Prediction =  331.05 , Y =  345.5\n",
      "Prediction =  238.42 , Y =  258.12\n",
      "Prediction =  317.83 , Y =  343.4\n",
      "Prediction =  301.25 , Y =  305.31\n",
      "Prediction =  247.5 , Y =  252.18\n",
      "Prediction =  247.57 , Y =  251.9\n",
      "Prediction =  292.72 , Y =  286.78\n",
      "Prediction =  325.26 , Y =  318.08\n",
      "Prediction =  202.65 , Y =  203.25\n",
      "Prediction =  302.02 , Y =  311.54\n",
      "Prediction =  340.54 , Y =  336.22\n",
      "Prediction =  324.09 , Y =  345.6\n",
      "Prediction =  300.12 , Y =  296.1\n",
      "Prediction =  421.54 , Y =  421.29\n",
      "Prediction =  254.21 , Y =  277.38\n",
      "Prediction =  913.81 , Y =  1027.48\n",
      "Prediction =  199.13 , Y =  207.75\n",
      "Prediction =  324.98 , Y =  337.46\n",
      "Prediction =  1620.01 , Y =  1626.42\n",
      "Prediction =  221.57 , Y =  229.8\n",
      "Prediction =  241.95 , Y =  245.6\n",
      "Prediction =  361.41 , Y =  377.44\n",
      "Prediction =  375.66 , Y =  376.4\n",
      "Prediction =  243.56 , Y =  261.0\n",
      "Prediction =  195.3 , Y =  210.84\n",
      "Prediction =  268.34 , Y =  280.16\n",
      "Prediction =  194.18 , Y =  195.0\n",
      "Prediction =  199.05 , Y =  198.5\n",
      "Prediction =  347.29 , Y =  371.9\n",
      "Prediction =  222.25 , Y =  227.77\n",
      "Prediction =  310.6 , Y =  327.66\n",
      "Prediction =  345.37 , Y =  353.1\n",
      "Prediction =  292.88 , Y =  303.0\n",
      "Prediction =  284.76 , Y =  283.72\n",
      "Prediction =  271.43 , Y =  281.16\n",
      "Prediction =  493.09 , Y =  515.49\n",
      "Prediction =  281.56 , Y =  309.28\n",
      "Prediction =  195.4 , Y =  204.45\n",
      "Prediction =  211.55 , Y =  223.4\n",
      "Prediction =  221.77 , Y =  224.83\n",
      "Prediction =  298.72 , Y =  306.89\n",
      "Prediction =  241.61 , Y =  246.95\n",
      "Prediction =  340.56 , Y =  349.05\n",
      "Prediction =  344.36 , Y =  360.5\n",
      "Prediction =  307.38 , Y =  316.5\n",
      "Prediction =  353.02 , Y =  344.49\n",
      "Prediction =  226.29 , Y =  222.24\n",
      "Prediction =  386.23 , Y =  413.0\n",
      "Prediction =  322.79 , Y =  337.0\n",
      "Prediction =  332.92 , Y =  324.45\n",
      "Prediction =  292.97 , Y =  274.88\n",
      "Prediction =  808.32 , Y =  769.75\n",
      "Prediction =  312.49 , Y =  325.5\n",
      "Prediction =  279.31 , Y =  291.99\n",
      "Prediction =  329.29 , Y =  342.0\n",
      "Prediction =  293.54 , Y =  304.6\n",
      "Prediction =  260.0 , Y =  248.36\n",
      "Prediction =  322.13 , Y =  320.75\n",
      "Prediction =  220.64 , Y =  223.8\n",
      "Prediction =  189.67 , Y =  193.46\n",
      "Prediction =  345.71 , Y =  344.7\n",
      "Prediction =  561.53 , Y =  564.44\n",
      "Prediction =  241.14 , Y =  253.53\n",
      "Prediction =  306.75 , Y =  304.6\n",
      "Prediction =  275.16 , Y =  295.01\n",
      "Prediction =  248.17 , Y =  253.28\n",
      "Prediction =  779.98 , Y =  690.52\n",
      "Prediction =  310.46 , Y =  315.5\n",
      "Prediction =  345.43 , Y =  344.0\n",
      "Prediction =  330.02 , Y =  345.0\n",
      "Prediction =  342.62 , Y =  363.71\n",
      "Prediction =  314.35 , Y =  323.51\n",
      "Prediction =  313.84 , Y =  326.72\n",
      "Prediction =  221.73 , Y =  206.0\n",
      "Prediction =  344.99 , Y =  357.59\n",
      "Prediction =  356.84 , Y =  370.0\n",
      "Prediction =  304.44 , Y =  308.45\n",
      "Prediction =  501.24 , Y =  494.26\n",
      "Prediction =  250.51 , Y =  262.1\n",
      "Prediction =  313.14 , Y =  334.66\n",
      "Prediction =  371.0 , Y =  376.83\n",
      "Prediction =  310.52 , Y =  318.0\n",
      "Prediction =  268.81 , Y =  306.26\n",
      "Prediction =  306.92 , Y =  318.0\n",
      "Prediction =  356.43 , Y =  366.65\n",
      "Prediction =  256.34 , Y =  246.68\n",
      "Prediction =  356.16 , Y =  365.49\n",
      "Prediction =  239.46 , Y =  240.0\n",
      "Prediction =  330.22 , Y =  331.26\n",
      "Prediction =  245.43 , Y =  243.68\n",
      "Prediction =  316.61 , Y =  294.5\n",
      "Prediction =  205.09 , Y =  220.9\n",
      "Prediction =  356.87 , Y =  361.26\n",
      "Prediction =  306.63 , Y =  310.32\n",
      "Prediction =  219.22 , Y =  229.09\n",
      "Prediction =  769.73 , Y =  824.0\n",
      "Prediction =  409.83 , Y =  433.48\n",
      "Prediction =  453.53 , Y =  557.0\n",
      "Prediction =  368.79 , Y =  385.0\n",
      "Prediction =  251.56 , Y =  262.15\n",
      "Prediction =  340.54 , Y =  350.85\n",
      "Prediction =  340.2 , Y =  327.13\n",
      "Prediction =  180.19 , Y =  189.49\n",
      "Prediction =  345.81 , Y =  351.75\n",
      "Prediction =  231.91 , Y =  248.68\n",
      "Prediction =  560.32 , Y =  589.8\n",
      "Prediction =  285.32 , Y =  291.17\n",
      "Prediction =  331.18 , Y =  332.5\n",
      "Prediction =  313.42 , Y =  336.24\n",
      "Prediction =  227.88 , Y =  236.0\n",
      "Prediction =  744.43 , Y =  734.0\n",
      "Prediction =  346.13 , Y =  355.24\n",
      "Prediction =  305.33 , Y =  316.98\n",
      "Prediction =  227.31 , Y =  231.0\n",
      "Prediction =  355.48 , Y =  354.0\n",
      "Prediction =  235.29 , Y =  235.94\n",
      "Prediction =  261.44 , Y =  273.35\n",
      "Prediction =  219.32 , Y =  225.17\n",
      "Prediction =  325.16 , Y =  344.81\n",
      "Prediction =  299.62 , Y =  330.0\n",
      "Prediction =  314.84 , Y =  327.28\n",
      "Prediction =  282.04 , Y =  298.73\n",
      "Prediction =  312.16 , Y =  319.58\n",
      "Prediction =  364.6 , Y =  366.77\n",
      "Prediction =  312.72 , Y =  316.41\n",
      "Prediction =  353.75 , Y =  382.64\n",
      "Prediction =  588.77 , Y =  741.88\n",
      "Prediction =  316.26 , Y =  327.32\n",
      "Prediction =  326.3 , Y =  336.38\n",
      "Prediction =  200.39 , Y =  212.23\n",
      "Prediction =  356.83 , Y =  359.2\n",
      "Prediction =  241.64 , Y =  258.55\n",
      "Prediction =  308.33 , Y =  314.7\n",
      "Prediction =  344.35 , Y =  368.58\n",
      "Prediction =  264.91 , Y =  265.51\n",
      "Prediction =  321.0 , Y =  308.69\n",
      "Prediction =  322.96 , Y =  343.5\n",
      "Prediction =  343.9 , Y =  342.8\n",
      "Prediction =  219.06 , Y =  222.86\n",
      "Prediction =  321.71 , Y =  317.68\n",
      "Prediction =  274.57 , Y =  280.0\n",
      "Prediction =  314.02 , Y =  314.63\n",
      "Prediction =  219.19 , Y =  228.49\n",
      "Prediction =  353.25 , Y =  338.47\n",
      "Prediction =  270.46 , Y =  270.5\n",
      "Prediction =  251.52 , Y =  251.0\n",
      "Prediction =  305.02 , Y =  321.99\n",
      "Prediction =  256.08 , Y =  234.5\n",
      "Prediction =  807.0 , Y =  835.0\n",
      "Prediction =  342.16 , Y =  353.84\n",
      "Test set has cost =  0.012991659199745365\n"
     ]
    }
   ],
   "source": [
    "# Test on the test set:\n",
    "\n",
    "print(\"Test set results:\")\n",
    "\n",
    "data = numpy.zeros((numpy.size(Xtest,0), numpy.size(Xtest,1)))\n",
    "label = numpy.zeros((numpy.size(Ytest)))\n",
    "\n",
    "sumSqrError = 0\n",
    "for i in range(0, size_test):\n",
    "    sumSqrError += (Xtest[i] @ param - Ytest[i]) ** 2\n",
    "    \n",
    "    # Visualize result:\n",
    "    # Reverse normalization: \n",
    "    label[i] = Ytest[i] * numpy.std(Y) + numpy.mean(Y) \n",
    "    data[i,0] = 1.0\n",
    "    for j in range(1, num_features):\n",
    "        data[i,j] = Xtest[i,j] * X_std[0,j-1] + X_mean[0,j-1]  \n",
    "    # Output predicted stock prices of test set:\n",
    "    print(\"Prediction = \", round(data[i]@param, 2), \", Y = \", round(label[i], 2))\n",
    "\n",
    "# Cost calculation:\n",
    "sumSqrParam = 0\n",
    "for j in range(1, num_features):\n",
    "    sumSqrParam += param[j] ** 2\n",
    "\n",
    "cost = (1/(2*size_test)) * sumSqrError + lam_list[lam_opt_index] * sumSqrParam\n",
    "\n",
    "print(\"Test set has cost = \", cost, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 1.37779004e+03 1.42950000e+03 1.41726001e+03\n",
      "  1.40856006e+03 1.54892004e+03 1.79498999e+03 1.59000000e+03\n",
      "  1.55000000e+03 1.53170996e+03 1.53751001e+03 1.65000000e+03\n",
      "  1.67500000e+03 1.62642004e+03 1.68900000e+03 1.46500000e+03]]\n",
      "July 27th 2020's price will be  [1543.48248516]\n"
     ]
    }
   ],
   "source": [
    "# Predict tomorrow's price:\n",
    "recent = numpy.zeros((1, num_features), dtype=float) \n",
    "    # The most recent \"lag\" amount of prices\n",
    "    \n",
    "for j in range(0, num_features-1):\n",
    "    recent[0,j] = X[-1,j]\n",
    "\n",
    "recent[0,0] = 1.0\n",
    "recent[0,-1] = Y[-1] # The last feature is the current price\n",
    "print(recent)\n",
    "\n",
    "prediction = recent @ param\n",
    "print(\"On July 27th 2020, TSLA highest price will be \", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
